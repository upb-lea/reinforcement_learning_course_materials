{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-talk')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import deque\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "    (\"rbf0\", RBFSampler(gamma=5.0, n_components = 100)),\n",
    "    (\"rbf1\", RBFSampler(gamma=2.0, n_components = 100)),\n",
    "    (\"rbf2\", RBFSampler(gamma=1.0, n_components = 100)),\n",
    "    (\"rbf3\", RBFSampler(gamma=0.5, n_components = 100)),\n",
    "    ])\n",
    "featurizer.fit(scaler.transform(observation_examples))\n",
    "\n",
    "\n",
    "def featurize(state):\n",
    "    try:\n",
    "        scaled = scaler.transform([state])\n",
    "    except:\n",
    "        print(state)\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa_lambda(nb_episodes, alpha, _lambda):\n",
    "    # alpha = 0.0001\n",
    "    gamma = 1\n",
    "    # _lambda = 0.0\n",
    "    epsilon = 0.15\n",
    "    #nb_episodes = 100\n",
    "\n",
    "    env = gym.make('MountainCar-v0')\n",
    "\n",
    "    state = env.reset()\n",
    "    norm_state = featurize(state)\n",
    "    input_dim = len(norm_state[0])\n",
    "\n",
    "\n",
    "    # define ANN topology\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    opt = SGD(learning_rate=alpha)\n",
    "\n",
    "    needed_steps_lambda = []\n",
    "\n",
    "    for j in tqdm(range(nb_episodes)):\n",
    "        k = 0\n",
    "        rewards = 0\n",
    "\n",
    "        # initialize z to zero; \n",
    "        # needs to be done in a loop because get_weights and gradients are lists \n",
    "        # of arrays that preserve the structure of the ANN\n",
    "        z = model.get_weights()\n",
    "        #print(z)\n",
    "        for i in range(len(z)):\n",
    "            z[i] = z[i] * 0\n",
    "\n",
    "        state = env.reset()\n",
    "        norm_state = featurize(state)\n",
    "\n",
    "        action_values = np.squeeze(model(norm_state).numpy())\n",
    "\n",
    "        # Choose Initial Action greedy\n",
    "        if epsilon < np.random.rand(1):\n",
    "            action = np.argmax(action_values)\n",
    "        else:\n",
    "            action = random.choice(range(3))\n",
    "\n",
    "        while True:\n",
    "            #env.render()\n",
    "\n",
    "            k += 1\n",
    "\n",
    "            ### STEP        \n",
    "            next_state, reward, done, _ = env.step(action)            \n",
    "            norm_next_state= featurize(next_state)\n",
    "            rewards += reward\n",
    "\n",
    "\n",
    "            action_value = np.squeeze(model(norm_state).numpy())[action]\n",
    "            if done:\n",
    "                target = reward\n",
    "            else:\n",
    "                # epsilon greedy action selection\n",
    "                next_action_values = np.squeeze(model(norm_next_state).numpy())\n",
    "                if epsilon < np.random.rand(1):\n",
    "                    next_action = np.argmax(next_action_values)\n",
    "                else:\n",
    "                    next_action = random.choice(range(3))\n",
    "\n",
    "                next_action_value = next_action_values[next_action]\n",
    "\n",
    "                target = reward + gamma * next_action_value\n",
    "\n",
    "            ### LEARN\n",
    "            delta = target - action_value\n",
    "            #print(delta)\n",
    "            with tf.GradientTape() as tape:\n",
    "                action_values = model(norm_state)\n",
    "                loss = mse(np.array([target]), action_values[0][action])\n",
    "\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            #print(gradients)\n",
    "            w = model.get_weights()\n",
    "            for i in range(len(z)):\n",
    "                z[i] = gamma * _lambda * z[i] + gradients[i] / delta\n",
    "                w[i] -= alpha * delta * z[i]\n",
    "            model.set_weights(w)\n",
    "            #opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            norm_state = norm_next_state\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "\n",
    "            if done:\n",
    "                needed_steps_lambda.append(k)\n",
    "                #print(f\"episode length {k}\")\n",
    "                if j % 10 == 0:\n",
    "                    #plot_surface(model, input_dim)\n",
    "                    pass\n",
    "                break            \n",
    "\n",
    "        env.close()\n",
    "    return needed_steps_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#head = [\"alpha\", \"lambda\", \"run\", \"episode_history\"]\n",
    "\n",
    "#file = open('ANN_sarsa_lambda_hyperopt_Samples50_alpha1e-4.csv', 'w') \n",
    "\n",
    "#with file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerow(head)\n",
    "\n",
    "nb_episodes = 500\n",
    "episodes = np.arange(0, nb_episodes, 1)\n",
    "tries = np.arange(0, 50, 1)\n",
    "\n",
    "#lambda_step = 0.05\n",
    "lambdas = np.array([0.1, 0.25, 0.4])# np.arange(0, 0.3 + lambda_step, lambda_step)\n",
    "\n",
    "#alpha_step0 = 2.5e-5\n",
    "#alphas0 = np.arange(alpha_step0, 1e-4 + alpha_step0, alpha_step0)\n",
    "#alpha_step1 = 2.5e-4\n",
    "#alphas1 = np.arange(alpha_step1, 1e-3 + alpha_step1, alpha_step1)\n",
    "alphas = [0.0001] #np.concatenate((alphas0, alphas1))\n",
    "\n",
    "for alpha in tqdm(alphas):\n",
    "    for _lambda in lambdas:\n",
    "        print(\"starting\")\n",
    "        a = time.time()\n",
    "        results = Parallel(n_jobs=6)(delayed(sarsa_lambda)(nb_episodes, alpha, _lambda) for run in tries)\n",
    "        print(\"ending\")\n",
    "        print(f\"took {time.time()-a} seconds\")\n",
    "        \n",
    "        for run, res in enumerate(results):\n",
    "            #res = sarsa_lambda(nb_episodes, alpha, _lambda)\n",
    "            dataseries = np.concatenate(([alpha], [_lambda], [int(run)], res))\n",
    "            file =  open('ANN_sarsa_lambda_hyperopt_Samples50_alpha1e-4.csv', 'a')\n",
    "            with file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(dataseries)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "table = None\n",
    "\n",
    "with open('linear_sarsa_lambda.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            if row != []:\n",
    "                if np.any(table == None):\n",
    "                    table = np.array([row])\n",
    "                else:\n",
    "                    table = np.append(table, [row], axis = 0)\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')\n",
    "    \n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.unique(table[:, 0])\n",
    "lambdas = np.unique(table[:, 1])\n",
    "\n",
    "mean_table = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    for _lambda in lambdas:\n",
    "        accumulate = None\n",
    "        for row in table:\n",
    "            if row[0] == alpha and row[1] == _lambda:\n",
    "                if np.any(accumulate == None):\n",
    "                    accumulate = row[3:].astype(np.float32)\n",
    "                else:\n",
    "                    accumulate += row[3:].astype(np.float32)\n",
    "                \n",
    "        accumulate /= 50\n",
    "        mean_row = np.concatenate(([alpha], [_lambda], accumulate))\n",
    "        if np.any(mean_table == None):\n",
    "            mean_table = np.array([mean_row])\n",
    "        else:\n",
    "            mean_table = np.append(mean_table, [mean_row], axis = 0)\n",
    "print(mean_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.unique(table[:, 0])\n",
    "lambdas = np.unique(table[:, 1])\n",
    "\n",
    "for alpha in alphas:\n",
    "    fig = plt.figure()\n",
    "    print(f\"alpha = {alpha}\")\n",
    "    for _lambda in lambdas: \n",
    "        for row in mean_table:\n",
    "            if row[0] == alpha and row[1] == _lambda and (_lambda.astype(np.float32) == 0.0 or _lambda.astype(np.float32) == 0.25 or _lambda.astype(np.float32) >= 0.8 and _lambda.astype(np.float32) <= 0.85):\n",
    "                plt.plot(np.squeeze(row[2:].astype(np.float32)), label=fr\"$\\lambda =${_lambda}\")\n",
    "    plt.xlim([000, 500])\n",
    "    plt.ylim([140, 200])\n",
    "    plt.xlabel(\"episodes\")\n",
    "    plt.ylabel(\"episode length\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "    (\"rbf0\", RBFSampler(gamma=5.0, n_components = 100)),\n",
    "    (\"rbf1\", RBFSampler(gamma=2.0, n_components = 100)),\n",
    "    (\"rbf2\", RBFSampler(gamma=1.0, n_components = 100)),\n",
    "    (\"rbf3\", RBFSampler(gamma=0.5, n_components = 100)),\n",
    "    ])\n",
    "featurizer.fit(scaler.transform(observation_examples))\n",
    "\n",
    "\n",
    "def featurize(state, action):\n",
    "    action_vec = np.zeros([3, 1])\n",
    "    action_vec[action] = 1\n",
    "    \n",
    "    win = 0\n",
    "    if state[0] > 0.5:\n",
    "        win = 1\n",
    "    \n",
    "    try:\n",
    "        scaled = scaler.transform([state])\n",
    "    except:\n",
    "        print(state)\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    featurized = np.reshape(featurized, (-1, 1)) # make column vector\n",
    "    \n",
    "    featurized = np.append(featurized, np.array([[1]]), axis = 0)\n",
    "    \n",
    "    featurized_vec = np.array([])\n",
    "    featurized_vec = np.expand_dims(featurized_vec, axis=-1)\n",
    "    for a in action_vec:\n",
    "        if a == 1:\n",
    "            featurized_vec = np.append(featurized_vec, featurized, axis = 0)\n",
    "        elif a == 0:\n",
    "            featurized_vec = np.append(featurized_vec, np.zeros([len(featurized), 1]), axis = 0)        \n",
    "    \n",
    "    return featurized_vec * (1 - win) # append the action to the column vector\n",
    "\n",
    "\n",
    "def policy(state, w, n, epsilon):\n",
    "    feat_states = np.zeros([len(w), n, 1])\n",
    "    q_value = np.zeros([n])\n",
    "\n",
    "    for i in range(n):    \n",
    "        feat_state = featurize(state, i)\n",
    "        feat_states[:, i] = feat_state\n",
    "        q_value[i] = np.transpose(feat_state) @ w\n",
    "            \n",
    "    if epsilon < np.random.rand(1):\n",
    "        action = np.argmax(q_value)\n",
    "    else:\n",
    "        action = random.choice(range(n))\n",
    "        \n",
    "    return feat_states[:, action], action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueOnline_SARSA(nb_episodes, alpha, _lambda):\n",
    "\n",
    "    #alpha = 0.01\n",
    "    gamma = 1\n",
    "    # _lambda = 0.1 # we call it like that because lambda is a defined command in python\n",
    "    epsilon = 0.15\n",
    "    #nb_episodes = 100\n",
    "\n",
    "    env = gym.make('MountainCar-v0')\n",
    "    state = env.reset()\n",
    "    feat_state = featurize(state, 0)\n",
    "    feat_dims = len(feat_state)\n",
    "\n",
    "    w = np.zeros(feat_dims)\n",
    "    w = np.expand_dims(w, axis=-1)\n",
    "\n",
    "    needed_steps_lambda = []\n",
    "\n",
    "    k = 0\n",
    "    for j in tqdm(range(nb_episodes)):\n",
    "        length = 0\n",
    "\n",
    "        state = env.reset()\n",
    "        feat_state, action = policy(state, w, env.action_space.n, epsilon)\n",
    "\n",
    "        q_old = 0\n",
    "        z = np.zeros_like(feat_state)\n",
    "\n",
    "        while True:\n",
    "            #env.render()\n",
    "            length += 1\n",
    "\n",
    "            # STEP\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            feat_next_state, next_action = policy(next_state, w, env.action_space.n, epsilon)\n",
    "\n",
    "\n",
    "            # LEARN\n",
    "            q = np.transpose(w) @ feat_state\n",
    "            q_prime = np.transpose(w) @ feat_next_state\n",
    "            delta = reward + gamma * q_prime - q\n",
    "            z = gamma * _lambda * z + (1 - alpha * gamma * _lambda * np.transpose(feat_state) @ z) * feat_state\n",
    "            w = w + alpha * (delta + q - q_old) * z - alpha * (q - q_old) * feat_state\n",
    "            q_old = q_prime\n",
    "\n",
    "\n",
    "            feat_state = feat_next_state\n",
    "            state = next_state\n",
    "            action = next_action\n",
    "\n",
    "            if done:\n",
    "                #print(f\"Episode: {j}, Length {length}\")\n",
    "                needed_steps_lambda.append(length)\n",
    "                if j % 10 == 0:\n",
    "                    # plot_surface_LSPI(w, feat_dims)\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    return needed_steps_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#head = [\"alpha\", \"lambda\", \"run\", \"episode_history\"]\n",
    "\n",
    "#file = open('linear_sarsa_lambda.csv', 'w') \n",
    "\n",
    "#with file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerow(head)\n",
    "\n",
    "nb_episodes = 500\n",
    "episodes = np.arange(0, nb_episodes, 1)\n",
    "tries = np.arange(0, 50, 1)\n",
    "\n",
    "#lambda_step = 0.05\n",
    "lambdas = np.array([0.8, 0.9, 0.95])# np.arange(0, 0.3 + lambda_step, lambda_step)\n",
    "\n",
    "#alpha_step0 = 2.5e-5\n",
    "#alphas0 = np.arange(alpha_step0, 1e-4 + alpha_step0, alpha_step0)\n",
    "#alpha_step1 = 2.5e-4\n",
    "#alphas1 = np.arange(alpha_step1, 1e-3 + alpha_step1, alpha_step1)\n",
    "alphas = [0.01] #np.concatenate((alphas0, alphas1))\n",
    "\n",
    "for alpha in tqdm(alphas):\n",
    "    for _lambda in lambdas:\n",
    "        print(\"starting\")\n",
    "        a = time.time()\n",
    "        results = Parallel(n_jobs=6)(delayed(trueOnline_SARSA)(nb_episodes, alpha, _lambda) for run in tries)\n",
    "        print(\"ending\")\n",
    "        print(f\"took {time.time()-a} seconds\")\n",
    "        \n",
    "        for run, res in enumerate(results):\n",
    "            #res = sarsa_lambda(nb_episodes, alpha, _lambda)\n",
    "            dataseries = np.concatenate(([alpha], [_lambda], [int(run)], res))\n",
    "            file =  open('linear_sarsa_lambda.csv', 'a')\n",
    "            with file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(dataseries)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
